{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b5e89f",
   "metadata": {},
   "source": [
    "# ðŸ”„ Cyclic Training/Testing for Federated Learning with CUAV Attack\n",
    "\n",
    "## Complete Implementation with 23 Graphs\n",
    "\n",
    "This notebook implements a **cyclic training â†’ testing â†’ training â†’ testing** workflow for comprehensive evaluation of Hierarchical Federated Learning under CUAV attack scenarios.\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "**Total Graphs: 23**\n",
    "\n",
    "#### Phase 1: Single Cluster Baseline (100 rounds)\n",
    "- 600 clients with Dirichlet partition (Î±=0.5)\n",
    "- Cyclic: Train Round 1 â†’ Test â†’ Train Round 2 â†’ Test â†’ ... â†’ Round 100\n",
    "- **Output:** 2 graphs (1 training, 1 testing)\n",
    "\n",
    "#### Phase 2: Multi-Cluster Normal Operation (100 rounds)\n",
    "- 3 clusters with equal client distribution\n",
    "- Training: Equal split only\n",
    "- Testing: Both Equal & Dirichlet splits\n",
    "- **Output:** 9 graphs\n",
    "  - 1 overall training graph\n",
    "  - 4 testing graphs (1 overall + 3 per-cluster) for Equal split\n",
    "  - 4 testing graphs (1 overall + 3 per-cluster) for Dirichlet split\n",
    "\n",
    "#### Phase 3: CH Compromise - Convergence Case (rounds 101-125)\n",
    "- Continue from Phase 2 (after 100 rounds)\n",
    "- CH0 compromised at round 111\n",
    "- Testing only (no new training graphs)\n",
    "- Flat lines for C0 during D&R-E phase\n",
    "- **Output:** 6 graphs\n",
    "  - 3 per-cluster testing graphs (C0, C1, C2) for Equal split\n",
    "  - 3 per-cluster testing graphs (C0, C1, C2) for Dirichlet split\n",
    "\n",
    "#### Phase 4: CH Compromise - Transient Case (fresh 30 rounds)\n",
    "- **New training session** (restart from scratch)\n",
    "- CH0 compromised at round 11\n",
    "- Testing only (no new training graphs)\n",
    "- **Output:** 6 graphs (same structure as Phase 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b97a8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a615c",
   "metadata": {},
   "source": [
    "## 2. Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c752c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== GLOBAL CONFIGURATION ====================\n",
    "\n",
    "# Data paths\n",
    "DATA_PATH = './datasets/local_cache/dataset_12500_samples_65_features.csv'\n",
    "RESULTS_DIR = './results_cyclic'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Model parameters\n",
    "INPUT_DIM = 64  # After dropping 'label'\n",
    "HIDDEN_DIM = 32\n",
    "OUTPUT_DIM = 2  # Binary classification\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Federated Learning parameters\n",
    "NUM_CLIENTS_SINGLE = 600  # Single cluster\n",
    "NUM_CLUSTERS = 3  # Multi-cluster\n",
    "CLIENTS_PER_CLUSTER = 200\n",
    "TOTAL_CLIENTS_MULTI = NUM_CLUSTERS * CLIENTS_PER_CLUSTER\n",
    "\n",
    "# Data split parameters\n",
    "DIRICHLET_ALPHA = 0.5  # For non-IID split\n",
    "TEST_SIZE = 0.2  # 20% for testing\n",
    "\n",
    "# Training parameters\n",
    "SINGLE_CLUSTER_ROUNDS = 100\n",
    "MULTI_CLUSTER_ROUNDS = 100\n",
    "COMPROMISE_CONVERGENCE_ROUNDS = 25  # Rounds 101-125\n",
    "COMPROMISE_TRANSIENT_ROUNDS = 30  # Fresh 30 rounds\n",
    "\n",
    "# Attack parameters\n",
    "CONVERGENCE_COMPROMISE_ROUND = 111  # During rounds 101-125\n",
    "CONVERGENCE_DETECTION_ROUND = 112\n",
    "CONVERGENCE_RECOVERY_START = 119\n",
    "CONVERGENCE_RECOVERY_END = 121\n",
    "\n",
    "TRANSIENT_COMPROMISE_ROUND = 11  # During fresh 30 rounds\n",
    "TRANSIENT_DETECTION_ROUND = 12\n",
    "TRANSIENT_RECOVERY_START = 19\n",
    "TRANSIENT_RECOVERY_END = 21\n",
    "\n",
    "# Target cluster for compromise\n",
    "COMPROMISED_CLUSTER = 0  # Cluster 0 (CH0)\n",
    "\n",
    "# Testing parameters\n",
    "TEST_SAMPLES = 2500  # Per test round\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Single Cluster: {NUM_CLIENTS_SINGLE} clients, {SINGLE_CLUSTER_ROUNDS} rounds\")\n",
    "print(f\"Multi-Cluster: {NUM_CLUSTERS} clusters Ã— {CLIENTS_PER_CLUSTER} clients = {TOTAL_CLIENTS_MULTI} total\")\n",
    "print(f\"Multi-Cluster Rounds: {MULTI_CLUSTER_ROUNDS}\")\n",
    "print(f\"Compromise Convergence: Rounds 101-125 (compromise at {CONVERGENCE_COMPROMISE_ROUND})\")\n",
    "print(f\"Compromise Transient: {COMPROMISE_TRANSIENT_ROUNDS} rounds (compromise at {TRANSIENT_COMPROMISE_ROUND})\")\n",
    "print(f\"Test samples per round: {TEST_SAMPLES}\")\n",
    "print(f\"Dirichlet Î±: {DIRICHLET_ALPHA}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e42e8f",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
